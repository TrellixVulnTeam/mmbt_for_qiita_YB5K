{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea56736f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atom\\git\\mmbt_for_qiita\\scripts\\ebay.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import shutil\n",
    "from scripts import ebay\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from PIL import Image\n",
    "import swifter\n",
    "import glob\n",
    "import mmbt.train_sales_forecast as train\n",
    "from mmbt.data import *\n",
    "from mmbt.data.helpers import get_data_loaders\n",
    "from mmbt.data.helpers import get_data_loaders_for_production\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#最大表示列数の指定（ここでは50列を指定）\n",
    "pd.set_option('display.max_columns', 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ae517c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e867a5df",
   "metadata": {},
   "source": [
    "# 関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034ada2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開けない画像がないか調査\n",
    "def error_imagefile_serch(fullpath):\n",
    "    path = './datasets/'+ fullpath\n",
    "    try:\n",
    "        image = Image.open(path)\n",
    "        return 0\n",
    "    except:\n",
    "        return 1\n",
    "    \n",
    "# pickleを保存\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, mode='wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "# pickleをロード\n",
    "def load_pickle(path):\n",
    "    with open(path, mode='rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "# 学習データ用の前処理\n",
    "def get_preprocessed_data(df,target_col):\n",
    "    \n",
    "    \n",
    "    # 前処理\n",
    "    df_tmp = df\n",
    "    # カテゴリー分類の際は、IDを指定する\n",
    "    if target_col == 'ctg':\n",
    "        df_tmp.ctg = df_tmp.ctg.astype(str)\n",
    "#             df_tmp = df_tmp[df_tmp['ctg'].isin(['69528','183454','180506','169291','15687'])]\n",
    "        df_tmp = df_tmp[df_tmp['ctg'].isin(['45258','15709','31387','52357'])]\n",
    "        \n",
    "    df_tmp[\"fullpath\"] = df_tmp.itemid.apply(lambda x: \"images/\" + str(x) + \".jpg\")\n",
    "\n",
    "    df_tmp['error_imgfile_flg'] = df_tmp['fullpath'].swifter.apply(lambda x:error_imagefile_serch(x))\n",
    "\n",
    "    df_tmp = df_tmp[df_tmp['error_imgfile_flg']==0]\n",
    "    df_tmp[\"label\"] = df_tmp[target_col]\n",
    "    df_tmp['img'] = './datasets/' + df_tmp['fullpath']\n",
    "    df_tmp[\"text\"] = df_tmp['title'].str.lower()\n",
    "    df_tmp[\"text\"] = df_tmp['text'].apply(lambda x: \" \".join(re.findall(r\"[ぁ-んァ-ン一-龥ー'\\da-zA-Z\\-]+\", x)))\n",
    "\n",
    "\n",
    "    df_preprocessed = df_tmp.loc[:,['ctg_name','label','text','img']].reset_index(drop=True)\n",
    "    df_preprocessed['key']=df_preprocessed.index\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    return df_preprocessed\n",
    "\n",
    "\n",
    "\n",
    "# 全ての画像ファイルのパスを取得\n",
    "def get_image_path_list(df):\n",
    "    df['img'] = './datasets/'+target_dataset+'/' + df['fullpath']\n",
    "    df['img_folda'] = df['img'].apply(lambda x:os.path.split(x)[0])\n",
    "    df['img_file_path_list'] = df['img_folda'].apply(lambda x:(glob.glob(x)))\n",
    "    return df\n",
    "\n",
    "# train,val,testデータを取得\n",
    "def get_dataset(df_preprocessed):\n",
    "    # 学習データとテストデータに分ける\n",
    "    df_train_dev,df_test = train_test_split(df_preprocessed, random_state=0,stratify=df_preprocessed.label)\n",
    "    # 最小データ数でダウンサンプリング\n",
    "    minimum_num = df_train_dev['label'].value_counts().min()\n",
    "    # ラベル毎に最小データ数だけサンプリング\n",
    "    dfs = [d.sample(minimum_num, random_state=0) for name, d in df_train_dev.groupby('label')]\n",
    "    # 結合。ラベル順に並んでいるのでshuffleする\n",
    "    under_resampled_df = pd.concat(dfs).sample(frac=1, random_state=0)\n",
    "    df_train_dev = under_resampled_df\n",
    "    df_train, df_dev = train_test_split(df_train_dev,stratify=df_train_dev.label)\n",
    "    data_dict = {\"train\": df_train, \"val\": df_dev,'test':df_test}\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "# aucを取得\n",
    "def get_roc_auc_score(detail_list):\n",
    "    y = detail_list[2]\n",
    "    pred = detail_list[3]\n",
    "    pred_0 = [x[1] for x in pred]\n",
    "    cleaned_pred_0 = [0 if str(x) == 'nan' else x for x in pred_0]\n",
    "    return roc_auc_score(y, cleaned_pred_0)\n",
    "\n",
    "# モデルのメタデータと評価をdfにまとめる\n",
    "def get_df_result(classification_report):\n",
    "    df_classification_report= pd.DataFrame(classification_report).transpose()\n",
    "    acc = df_classification_report.loc['accuracy']['support']\n",
    "    macro_f1 = df_classification_report.loc['macro avg']['f1-score']\n",
    "    model_name = 'model'+save_model_name+'.pt'\n",
    "    result_dict={'model_name':model_name,'target_col':target_col,\n",
    "                'batch_sz':batch_sz,'macro_f1':macro_f1,'accuracy':acc}\n",
    "    df_result = pd.DataFrame.from_dict(result_dict, orient='index').T\n",
    "    return df_result\n",
    "\n",
    "def save_classification_report(classification_report):\n",
    "    classification_report_dir = './classification_report/'\n",
    "    result_dir = './result/'\n",
    "    if not os.path.exists(classification_report_dir):\n",
    "        print(\"ディレクトリを作成します\")\n",
    "        os.makedirs(classification_report_dir)\n",
    "    # classification_reportの保存\n",
    "    save_pickle(classification_report,classification_report_dir+'/report_'+save_model_name+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3debf38d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 本番データでの予測の際に使用する関数\n",
    "# 予測値の確率を出力\n",
    "def get_preds_score(df,model_name):\n",
    "    target_dataset = 'ebay_20210822_msg_prediction' # データセット名\n",
    "    model = 'mmbt'\n",
    "    bert_model = 'bert-base-uncased' # bertモデル　bert-large-uncased　bert-base-uncased\n",
    "    image_model = 'resnet152' # imageモデル\n",
    "    batch_sz = '32' # 不要\n",
    "    max_epochs = '10' # 不要\n",
    "    target_col = 'none' # 不要\n",
    "    \n",
    "\n",
    "    # データ読み込み\n",
    "    df = df.loc[:][['mk_title','url','selling_price','category_id']]\n",
    "    df['title'] = df['mk_title']\n",
    "\n",
    "    # 前処理\n",
    "    categoryid = 'category_id'\n",
    "    price = 'selling_price'\n",
    "    df_preprocessed = get_preprocessed_data_for_production(df,target_dataset,categoryid,price)\n",
    "    # データセット作成＆保存\n",
    "    data_dict = get_dataset_for_production(df_preprocessed)\n",
    "    # モデルの各種設定\n",
    "    args = train.get_args(target_col,bert_model,batch_sz,max_epochs,model)\n",
    "    dataloaders_dict = get_data_loaders_for_production(args,data_dict)\n",
    "\n",
    "    # 評価\n",
    "    preds_score = train.production(args,model_name,dataloaders_dict,target_dataset)\n",
    "    df_preprocessed['preds_score'] = preds_score\n",
    "    df_preprocessed = df_preprocessed.reset_index(drop=True)\n",
    "    df_preprocessed\n",
    "    return df_preprocessed\n",
    "\n",
    "def get_df_addcol(df):\n",
    "    df_tmp = df\n",
    "    df_tmp[\"fullpath\"] = df_tmp.url.apply(lambda x: \"images/\" + x.split(\"/\")[-2] + \".jpg\")\n",
    "    df_tmp['error_imgfile_flg'] = df_tmp['fullpath'].swifter.apply(lambda x:error_imagefile_serch(x,target_dataset))\n",
    "    df_tmp['img'] = './datasets/'+target_dataset+'/' + df_tmp['fullpath']\n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "def get_first_pred_score(x):\n",
    "    try:\n",
    "        code_regex = re.compile('[\\'[\\]]')\n",
    "        cleaned_text = code_regex.sub('', x).split()[1]\n",
    "        return cleaned_text\n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "def get_pred(x):\n",
    "    try:\n",
    "        code_regex = re.compile('[\\'[\\]]')\n",
    "        cleaned_x_list = code_regex.sub('', x).split()\n",
    "        argmax_index = cleaned_x_list.index(max(cleaned_x_list))\n",
    "        return argmax_index\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b28542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_report(model):\n",
    "    args = train.get_args(target_col,bert_model,batch_sz,max_epochs,model,n_classes)\n",
    "    dataloaders_dict = get_data_loaders(args,data_dict)\n",
    "\n",
    "    # 学習\n",
    "    train.train(args,dataloaders_dict)\n",
    "\n",
    "    # モデルを名前を付けて保存\n",
    "    shutil.copyfile('./savedir/mmbt_model_run/model_best.pt','./savedir/mmbt_model_run/'+save_model_name+'.pt')\n",
    "\n",
    "    # 評価\n",
    "    classification_report,confusion_matrix,detail_list,attention_probs = train.test(args,save_model_name,dataloaders_dict)\n",
    "    # print(pd.DataFrame(classification_report).transpose())\n",
    "    # 保存\n",
    "    save_classification_report(classification_report)\n",
    "\n",
    "    # 結果を保存\n",
    "    df_result = get_df_result(classification_report)\n",
    "    result_dir = './result/'\n",
    "    save_pickle(df_result,result_dir+'df_result_'+save_model_name+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32553d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atom\\Anaconda3\\envs\\py385\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (5,7,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\atom\\AppData\\Local\\Temp/ipykernel_11056/817632162.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tmp[\"label\"] = df_tmp.category_id\n",
      "C:\\Users\\atom\\AppData\\Local\\Temp/ipykernel_11056/817632162.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tmp['img'] = './datasets/' + df_tmp['fullpath']\n",
      "C:\\Users\\atom\\AppData\\Local\\Temp/ipykernel_11056/817632162.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tmp[\"text\"] = df_tmp['title'].str.lower()\n",
      "C:\\Users\\atom\\AppData\\Local\\Temp/ipykernel_11056/817632162.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tmp[\"text\"] = df_tmp['text'].apply(lambda x: \" \".join(re.findall(r\"[ぁ-んァ-ン一-龥ー'\\da-zA-Z\\-]+\", x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ctg_name    False\n",
       "label       False\n",
       "text        False\n",
       "img         False\n",
       "key         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# カテゴリー番号、カテゴリー名のユニークなテーブルを作成\n",
    "df_sub = pd.read_table('./datasets/ebay_codes_20210815_message_prediction/data.tsv')\n",
    "df_uniques = df_sub[[\"ctg\", \"ctg_name\"]].drop_duplicates() \n",
    "# df_uniques.ctg = df_uniques.ctg.astype(str)\n",
    "\n",
    "\n",
    "# 前処理\n",
    "df = pd.read_table('./datasets/data.tsv')\n",
    "df_tmp = df\n",
    "df_tmp[\"fullpath\"] = df_tmp.img.apply(lambda x: \"images/\" + str(x))\n",
    "df_tmp = df_tmp[df_tmp['imgflg'] == True]\n",
    "\n",
    "# 画像ファイルが存在する行に絞る\n",
    "# df_tmp['error_imgfile_flg'] = df_tmp['fullpath'].swifter.apply(lambda x:error_imagefile_serch(x))\n",
    "# df_tmp = df_tmp[df_tmp['error_imgfile_flg']==0]\n",
    "\n",
    "df_tmp[\"label\"] = df_tmp.category_id\n",
    "df_tmp['img'] = './datasets/' + df_tmp['fullpath']\n",
    "df_tmp[\"text\"] = df_tmp['title'].str.lower()\n",
    "df_tmp[\"text\"] = df_tmp['text'].apply(lambda x: \" \".join(re.findall(r\"[ぁ-んァ-ン一-龥ー'\\da-zA-Z\\-]+\", x)))\n",
    "df_tmp = pd.merge(df_tmp,df_uniques,left_on='label',right_on='ctg',how='left')\n",
    "\n",
    "\n",
    "# カテゴリー数上位10に絞る\n",
    "df_category_cnt = df_tmp.category_id.value_counts().reset_index()\n",
    "df_category_cnt_top10 = df_category_cnt.iloc[0:10]\n",
    "df_category_cnt_top10 = df_category_cnt_top10.drop(columns='category_id')\n",
    "\n",
    "# カテゴリー数1000件以上に絞る\n",
    "# df_category_cnt_over1000 = df_tmp.category_id.value_counts().reset_index()\n",
    "# df_category_cnt_over1000 = df_category_cnt_over1000[df_category_cnt_over1000['category_id']>1000]\n",
    "# df_category_cnt_over1000 = df_category_cnt_over1000.drop(columns='category_id')\n",
    "\n",
    "# カテゴリー名を結合\n",
    "df_tmp = pd.merge(df_category_cnt_top10,df_tmp,left_on='index',right_on='category_id',how='left')\n",
    "# df_tmp = pd.merge(df_category_cnt_over1000,df_tmp,left_on='index',right_on='category_id',how='left')\n",
    "\n",
    "df_preprocessed = df_tmp.loc[:,['ctg_name','label','text','img']].reset_index(drop=True)\n",
    "df_preprocessed['key'] = df_preprocessed.index\n",
    "df_preprocessed.label= df_preprocessed.label.astype(str)\n",
    "df_preprocessed = df_preprocessed.dropna(how='any')\n",
    "df_preprocessed.to_csv('./datasets/data_preprocessed.csv')\n",
    "df_preprocessed.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9f592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dfffcb9",
   "metadata": {},
   "source": [
    "# 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d23d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:19:23 - 2:18:55 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\atom\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO - 11/17/21 00:19:23 - 2:18:56 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\atom\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO - 11/17/21 00:19:24 - 2:18:56 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\atom\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 11/17/21 00:19:24 - 2:18:56 - extracting archive file C:\\Users\\atom\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\atom\\AppData\\Local\\Temp\\tmpr3ta_e50\n",
      "INFO - 11/17/21 00:19:26 - 2:18:59 - Model config {\n",
      "                                       \"attention_probs_dropout_prob\": 0.1,\n",
      "                                       \"hidden_act\": \"gelu\",\n",
      "                                       \"hidden_dropout_prob\": 0.1,\n",
      "                                       \"hidden_size\": 768,\n",
      "                                       \"initializer_range\": 0.02,\n",
      "                                       \"intermediate_size\": 3072,\n",
      "                                       \"max_position_embeddings\": 512,\n",
      "                                       \"num_attention_heads\": 12,\n",
      "                                       \"num_hidden_layers\": 12,\n",
      "                                       \"type_vocab_size\": 2,\n",
      "                                       \"vocab_size\": 30522\n",
      "                                     }\n",
      "                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_head_size 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:19:28 - 0:00:00 - batch_cnt: 1\n",
      "                                     batch_sz: 4\n",
      "                                     bert_model: bert-base-uncased\n",
      "                                     data_path: ./datasets/food101\n",
      "                                     drop_img_percent: 0.0\n",
      "                                     dropout: 0.1\n",
      "                                     embed_sz: 300\n",
      "                                     freeze_img: 3\n",
      "                                     freeze_txt: 5\n",
      "                                     glove_path: ./glove_embeds/glove.840B.300d.txt\n",
      "                                     gradient_accumulation_steps: 40\n",
      "                                     hidden: []\n",
      "                                     hidden_sz: 768\n",
      "                                     i_epoch: 1\n",
      "                                     img_embed_pool_type: avg\n",
      "                                     img_hidden_sz: 2048\n",
      "                                     include_bn: True\n",
      "                                     label_freqs: Counter({'53557': 1728, '45258': 1728, '15662': 1728, '62107': 1728, '50637': 1728, '169291': 1728, '52357': 1728})\n",
      "                                     labels: ['15662', '169291', '45258', '50637', '52357', '53557', '62107']\n",
      "                                     lr: 5e-05\n",
      "                                     lr_factor: 0.5\n",
      "                                     lr_patience: 2\n",
      "                                     max_epochs: 20\n",
      "                                     max_seq_len: 512\n",
      "                                     model: mmbt\n",
      "                                     n_classes: 7\n",
      "                                     n_target_variables: 2\n",
      "                                     n_workers: 12\n",
      "                                     name: mmbt_model_run\n",
      "                                     num_image_embeds: 3\n",
      "                                     patience: 5\n",
      "                                     savedir: ./savedir/mmbt_model_run\n",
      "                                     seed: 1\n",
      "                                     task: mmimdb\n",
      "                                     task_type: classification\n",
      "                                     train_data_len: 12096\n",
      "                                     vocab: <mmbt.data.vocab.Vocab object at 0x00000286E9D5A9D0>\n",
      "                                     vocab_sz: 30522\n",
      "                                     warmup: 0.1\n",
      "                                     weight_classes: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:19:28 - 0:00:00 - Training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習0回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:23:54 - 0:04:26 - Train Loss: 0.0374\n",
      "INFO - 11/17/21 00:23:54 - 0:04:26 - Val: Loss: 0.96349 | Acc: 0.66295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習1回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:28:22 - 0:08:54 - Train Loss: 0.0167\n",
      "INFO - 11/17/21 00:28:22 - 0:08:54 - Val: Loss: 0.37451 | Acc: 0.87103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習2回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:33:02 - 0:13:34 - Train Loss: 0.0085\n",
      "INFO - 11/17/21 00:33:02 - 0:13:34 - Val: Loss: 0.26158 | Acc: 0.91220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習3回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:40:23 - 0:20:55 - Train Loss: 0.0060\n",
      "INFO - 11/17/21 00:40:23 - 0:20:55 - Val: Loss: 0.23473 | Acc: 0.92510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習4回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:47:24 - 0:27:56 - Train Loss: 0.0046\n",
      "INFO - 11/17/21 00:47:24 - 0:27:56 - Val: Loss: 0.24535 | Acc: 0.91939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習5回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 00:54:52 - 0:35:24 - Train Loss: 0.0043\n",
      "INFO - 11/17/21 00:54:52 - 0:35:24 - Val: Loss: 0.25764 | Acc: 0.91716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習6回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:02:21 - 0:42:53 - Train Loss: 0.0030\n",
      "INFO - 11/17/21 01:02:21 - 0:42:53 - Val: Loss: 0.23941 | Acc: 0.93006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習7回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:09:47 - 0:50:19 - Train Loss: 0.0019\n",
      "INFO - 11/17/21 01:09:47 - 0:50:19 - Val: Loss: 0.22983 | Acc: 0.93651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習8回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:17:16 - 0:57:48 - Train Loss: 0.0012\n",
      "INFO - 11/17/21 01:17:16 - 0:57:48 - Val: Loss: 0.26248 | Acc: 0.93403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習9回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:24:42 - 1:05:14 - Train Loss: 0.0009\n",
      "INFO - 11/17/21 01:24:42 - 1:05:14 - Val: Loss: 0.24551 | Acc: 0.93874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習10回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:32:13 - 1:12:45 - Train Loss: 0.0006\n",
      "INFO - 11/17/21 01:32:13 - 1:12:45 - Val: Loss: 0.26373 | Acc: 0.94122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習11回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:39:48 - 1:20:20 - Train Loss: 0.0004\n",
      "INFO - 11/17/21 01:39:48 - 1:20:20 - Val: Loss: 0.26560 | Acc: 0.93948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習12回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:47:33 - 1:28:05 - Train Loss: 0.0002\n",
      "INFO - 11/17/21 01:47:33 - 1:28:05 - Val: Loss: 0.27715 | Acc: 0.93973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習13回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 01:54:56 - 1:35:28 - Train Loss: 0.0002\n",
      "INFO - 11/17/21 01:54:56 - 1:35:28 - Val: Loss: 0.27333 | Acc: 0.94271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習14回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:02:26 - 1:42:58 - Train Loss: 0.0002\n",
      "INFO - 11/17/21 02:02:26 - 1:42:58 - Val: Loss: 0.28671 | Acc: 0.94147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習15回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:09:48 - 1:50:20 - Train Loss: 0.0001\n",
      "INFO - 11/17/21 02:09:48 - 1:50:20 - Val: Loss: 0.30033 | Acc: 0.94444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習16回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:17:15 - 1:57:47 - Train Loss: 0.0001\n",
      "INFO - 11/17/21 02:17:15 - 1:57:47 - Val: Loss: 0.30658 | Acc: 0.94370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習17回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:24:43 - 2:05:15 - Train Loss: 0.0001\n",
      "INFO - 11/17/21 02:24:43 - 2:05:15 - Val: Loss: 0.32511 | Acc: 0.94320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習18回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:32:06 - 2:12:38 - Train Loss: 0.0001\n",
      "INFO - 11/17/21 02:32:06 - 2:12:38 - Val: Loss: 0.29964 | Acc: 0.94544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習19回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:39:32 - 2:20:04 - Train Loss: 0.0000\n",
      "INFO - 11/17/21 02:39:32 - 2:20:04 - Val: Loss: 0.29544 | Acc: 0.94643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:8412.821453094482[sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:39:39 - 2:20:11 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\atom\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 11/17/21 02:39:39 - 2:20:11 - extracting archive file C:\\Users\\atom\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\atom\\AppData\\Local\\Temp\\tmpjmp7caet\n",
      "INFO - 11/17/21 02:39:42 - 2:20:14 - Model config {\n",
      "                                       \"attention_probs_dropout_prob\": 0.1,\n",
      "                                       \"hidden_act\": \"gelu\",\n",
      "                                       \"hidden_dropout_prob\": 0.1,\n",
      "                                       \"hidden_size\": 768,\n",
      "                                       \"initializer_range\": 0.02,\n",
      "                                       \"intermediate_size\": 3072,\n",
      "                                       \"max_position_embeddings\": 512,\n",
      "                                       \"num_attention_heads\": 12,\n",
      "                                       \"num_hidden_layers\": 12,\n",
      "                                       \"type_vocab_size\": 2,\n",
      "                                       \"vocab_size\": 30522\n",
      "                                     }\n",
      "                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_head_size 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:41:27 - 2:21:59 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\atom\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO - 11/17/21 02:41:28 - 2:22:00 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\atom\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO - 11/17/21 02:41:29 - 2:22:01 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\atom\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO - 11/17/21 02:41:29 - 2:22:01 - extracting archive file C:\\Users\\atom\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\atom\\AppData\\Local\\Temp\\tmpznawjxca\n",
      "INFO - 11/17/21 02:41:31 - 2:22:03 - Model config {\n",
      "                                       \"attention_probs_dropout_prob\": 0.1,\n",
      "                                       \"hidden_act\": \"gelu\",\n",
      "                                       \"hidden_dropout_prob\": 0.1,\n",
      "                                       \"hidden_size\": 768,\n",
      "                                       \"initializer_range\": 0.02,\n",
      "                                       \"intermediate_size\": 3072,\n",
      "                                       \"max_position_embeddings\": 512,\n",
      "                                       \"num_attention_heads\": 12,\n",
      "                                       \"num_hidden_layers\": 12,\n",
      "                                       \"type_vocab_size\": 2,\n",
      "                                       \"vocab_size\": 30522\n",
      "                                     }\n",
      "                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_head_size 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:41:32 - 0:00:00 - batch_cnt: 1\n",
      "                                     batch_sz: 4\n",
      "                                     bert_model: bert-base-uncased\n",
      "                                     data_path: ./datasets/food101\n",
      "                                     drop_img_percent: 0.0\n",
      "                                     dropout: 0.1\n",
      "                                     embed_sz: 300\n",
      "                                     freeze_img: 3\n",
      "                                     freeze_txt: 5\n",
      "                                     glove_path: ./glove_embeds/glove.840B.300d.txt\n",
      "                                     gradient_accumulation_steps: 40\n",
      "                                     hidden: []\n",
      "                                     hidden_sz: 768\n",
      "                                     i_epoch: 1\n",
      "                                     img_embed_pool_type: avg\n",
      "                                     img_hidden_sz: 2048\n",
      "                                     include_bn: True\n",
      "                                     label_freqs: Counter({'53557': 1728, '45258': 1728, '15662': 1728, '62107': 1728, '50637': 1728, '169291': 1728, '52357': 1728})\n",
      "                                     labels: ['15662', '169291', '45258', '50637', '52357', '53557', '62107']\n",
      "                                     lr: 5e-05\n",
      "                                     lr_factor: 0.5\n",
      "                                     lr_patience: 2\n",
      "                                     max_epochs: 20\n",
      "                                     max_seq_len: 512\n",
      "                                     model: bert\n",
      "                                     n_classes: 7\n",
      "                                     n_target_variables: 2\n",
      "                                     n_workers: 12\n",
      "                                     name: mmbt_model_run\n",
      "                                     num_image_embeds: 3\n",
      "                                     patience: 5\n",
      "                                     savedir: ./savedir/mmbt_model_run\n",
      "                                     seed: 1\n",
      "                                     task: mmimdb\n",
      "                                     task_type: classification\n",
      "                                     train_data_len: 12096\n",
      "                                     vocab: <mmbt.data.vocab.Vocab object at 0x00000286E75256A0>\n",
      "                                     vocab_sz: 30522\n",
      "                                     warmup: 0.1\n",
      "                                     weight_classes: 1\n",
      "INFO - 11/17/21 02:41:32 - 0:00:00 - Training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n",
      "学習0回目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11/17/21 02:44:36 - 0:03:04 - Train Loss: 0.0248\n",
      "INFO - 11/17/21 02:44:36 - 0:03:04 - Val: Loss: 0.27729 | Acc: 0.91022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習1回目\n"
     ]
    }
   ],
   "source": [
    "# 変数設定\n",
    "target_col = 'ctg' # 目的変数のカラム名\n",
    "model = 'bert'# mmbt/img/bert/concatbert\n",
    "bert_model = 'bert-base-uncased' # bertモデル　bert-large-uncased　bert-base-uncased\n",
    "image_model = 'resnet152' # imageモデル ※将来的にresnet152以外のモデルを使う場合に使用\n",
    "batch_sz = '4' # 32 バッチサイズ\n",
    "max_epochs = '20' # 学習回数\n",
    "n_classes = '10'\n",
    "\n",
    "# データセット作成＆保存\n",
    "df_preprocessed = pd.read_csv('./datasets/data_preprocessed.csv', index_col=0,dtype = {'ctg_name':'object', 'label':'object', 'text':'object','img':'object','key':'int'})\n",
    "df_preprocessed = df_preprocessed.dropna(how='any')\n",
    "df_preprocessed = df_preprocessed.sample(n=30000)\n",
    "data_dict = get_dataset(df_preprocessed)\n",
    "# data_dict = load_pickle('./tmp/data_dict.pkl')\n",
    "save_pickle(data_dict,'./tmp/data_dict.pkl')\n",
    "model_list = ['mmbt','bert','img','concatbert']\n",
    "# model_list = ['concatbert','mmbt'] \n",
    "# model_list = ['mmbt']\n",
    "for model in model_list:\n",
    "    save_model_name = model+'_'+target_col +'_'+ n_classes+'classes'#保存するモデル名\n",
    "    train_and_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf019d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c58adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['mmbt']\n",
    "for model in model_list:\n",
    "    save_model_name = model+'_'+target_col +'_'+ n_classes+'classes'#保存するモデル名\n",
    "    train_and_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb9a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa34646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_bert_ctg_10classes = load_pickle('./result/df_result_bert_ctg_10classes.pkl')\n",
    "df_result_bert_ctg_10classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_bert_ctg_34classes = load_pickle('./result/df_result_bert_ctg_34classes.pkl')\n",
    "df_result_bert_ctg_34classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_img_ctg_34classes = load_pickle('./result/df_result_img_ctg_34classes.pkl')\n",
    "df_result_img_ctg_34classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_bert_ctg_34classes = load_pickle('./result/df_result_bert_ctg_34classes.pkl')\n",
    "df_result_img_ctg_34classes = load_pickle('./result/df_result_img_ctg_34classes.pkl')\n",
    "df_result_concatbert_ctg_34classes = load_pickle('./result/df_result_concatbert_ctg_34classes.pkl')\n",
    "df_result_mmbt_ctg_34classes = load_pickle('./result/df_result_mmbt_ctg_34classes.pkl')\n",
    "df_result_total = pd.concat([df_result_bert_ctg_34classes,df_result_img_ctg_34classes,df_result_concatbert_ctg_34classes,df_result_mmbt_ctg_34classes])\n",
    "df_result_total.sort_values('macro_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c88160a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>target_col</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelmmbt_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.900551</td>\n",
       "      <td>0.9016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelbert_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.897096</td>\n",
       "      <td>0.8984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelconcatbert_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.881301</td>\n",
       "      <td>0.8816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelimg_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.777782</td>\n",
       "      <td>0.7776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model_name target_col batch_sz  macro_f1 accuracy\n",
       "0        modelmmbt_ctg_10classes.pt        ctg        4  0.900551   0.9016\n",
       "0        modelbert_ctg_10classes.pt        ctg        4  0.897096   0.8984\n",
       "0  modelconcatbert_ctg_10classes.pt        ctg        4  0.881301   0.8816\n",
       "0         modelimg_ctg_10classes.pt        ctg        4  0.777782   0.7776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_bert_ctg_10classes = load_pickle('./result/df_result_bert_ctg_10classes.pkl')\n",
    "df_result_img_ctg_10classes = load_pickle('./result/df_result_img_ctg_10classes.pkl')\n",
    "df_result_concatbert_ctg_10classes = load_pickle('./result/df_result_concatbert_ctg_10classes.pkl')\n",
    "df_result_mmbt_ctg_10classes = load_pickle('./result/df_result_mmbt_ctg_10classes.pkl')\n",
    "df_result_total = pd.concat([df_result_bert_ctg_10classes,df_result_img_ctg_10classes,df_result_concatbert_ctg_10classes,df_result_mmbt_ctg_10classes])\n",
    "df_result_total.sort_values('macro_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc9a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>target_col</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelmmbt_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.931266</td>\n",
       "      <td>0.9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelconcatbert_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927045</td>\n",
       "      <td>0.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelbert_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922909</td>\n",
       "      <td>0.924533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelimg_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828503</td>\n",
       "      <td>0.8312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model_name target_col batch_sz  macro_f1  accuracy\n",
       "0        modelmmbt_ctg_10classes.pt        ctg        4  0.931266    0.9312\n",
       "0  modelconcatbert_ctg_10classes.pt        ctg        4  0.927045  0.926667\n",
       "0        modelbert_ctg_10classes.pt        ctg        4  0.922909  0.924533\n",
       "0         modelimg_ctg_10classes.pt        ctg        4  0.828503    0.8312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_bert_ctg_10classes = load_pickle('./result/df_result_bert_ctg_10classes.pkl')\n",
    "df_result_img_ctg_10classes = load_pickle('./result/df_result_img_ctg_10classes.pkl')\n",
    "df_result_concatbert_ctg_10classes = load_pickle('./result/df_result_concatbert_ctg_10classes.pkl')\n",
    "df_result_mmbt_ctg_10classes = load_pickle('./result/df_result_mmbt_ctg_10classes.pkl')\n",
    "df_result_total = pd.concat([df_result_bert_ctg_10classes,df_result_img_ctg_10classes,df_result_concatbert_ctg_10classes,df_result_mmbt_ctg_10classes])\n",
    "df_result_total.sort_values('macro_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc73582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>target_col</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelmmbt_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.939516</td>\n",
       "      <td>0.9396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelconcatbert_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927045</td>\n",
       "      <td>0.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelbert_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922909</td>\n",
       "      <td>0.924533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelimg_ctg_10classes.pt</td>\n",
       "      <td>ctg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828503</td>\n",
       "      <td>0.8312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model_name target_col batch_sz  macro_f1  accuracy\n",
       "0        modelmmbt_ctg_10classes.pt        ctg        4  0.939516    0.9396\n",
       "0  modelconcatbert_ctg_10classes.pt        ctg        4  0.927045  0.926667\n",
       "0        modelbert_ctg_10classes.pt        ctg        4  0.922909  0.924533\n",
       "0         modelimg_ctg_10classes.pt        ctg        4  0.828503    0.8312"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_bert_ctg_10classes = load_pickle('./result/df_result_bert_ctg_10classes.pkl')\n",
    "df_result_img_ctg_10classes = load_pickle('./result/df_result_img_ctg_10classes.pkl')\n",
    "df_result_concatbert_ctg_10classes = load_pickle('./result/df_result_concatbert_ctg_10classes.pkl')\n",
    "df_result_mmbt_ctg_10classes = load_pickle('./result/df_result_mmbt_ctg_10classes.pkl')\n",
    "df_result_total = pd.concat([df_result_bert_ctg_10classes,df_result_img_ctg_10classes,df_result_concatbert_ctg_10classes,df_result_mmbt_ctg_10classes])\n",
    "df_result_total.sort_values('macro_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8401aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'new_block' on <module 'pandas.core.internals.blocks' from 'C:\\\\Users\\\\atom\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\internals\\\\blocks.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dd31616548d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_result_mmbt_ctg_10classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./result/df_result_mmbt_ctg_10classes.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-4b0d9e3af144>\u001b[0m in \u001b[0;36mload_pickle\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'new_block' on <module 'pandas.core.internals.blocks' from 'C:\\\\Users\\\\atom\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\internals\\\\blocks.py'>"
     ]
    }
   ],
   "source": [
    "df_result_mmbt_ctg_10classes = load_pickle('./result/df_result_mmbt_ctg_10classes.pkl')\n",
    "df_result_mmbt_ctg_10classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed75dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_bert_ctg_4classes = load_pickle('./result/df_result_bert_ctg_4classes.pkl')\n",
    "df_result_img_ctg_4classes = load_pickle('./result/df_result_img_ctg_4classes.pkl')\n",
    "df_result_concatbert_ctg_4classes = load_pickle('./result/df_result_concatbert_ctg_4classes.pkl')\n",
    "df_result_mmbt_ctg_4classes = load_pickle('./result/df_result_mmbt_ctg_4classes.pkl')\n",
    "df_result_total = pd.concat([df_result_bert_ctg_4classes,df_result_img_ctg_4classes,df_result_concatbert_ctg_4classes,df_result_mmbt_ctg_4classes])\n",
    "df_result_total.sort_values('macro_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4685b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782730c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd7a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfed97",
   "metadata": {},
   "source": [
    "# モデル単体で実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fc172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # データ読み込み\n",
    "# df = pd.read_table('./datasets/data.tsv')\n",
    "# # 前処理\n",
    "# df_preprocessed = get_preprocessed_data(df,target_col)\n",
    "# # データセット作成＆保存\n",
    "data_dict = get_dataset(df_preprocessed)\n",
    "# save_pickle(data_dict,'./tmp/data_dict.pkl')\n",
    "\n",
    "# 変数設定\n",
    "target_dataset = 'ebay_codes_20210815_message_prediction' # データセット名\n",
    "target_col = 'ctg' #目的変数のカラム名\n",
    "model = 'mmbt'# mmbt/img/bert/concatbert\n",
    "bert_model = 'bert-base-uncased' # bertモデル　bert-large-uncased　bert-base-uncased\n",
    "image_model = 'resnet152' # imageモデル ※将来的にresnet152以外のモデルを使う場合に使用\n",
    "batch_sz = '32' #　32 バッチサイズ\n",
    "max_epochs = '20' # 学習回数\n",
    "n_classes = '20'\n",
    "save_model_name = model+'_'+target_col +'_'+ n_classes+'classes'#保存するモデル名\n",
    "\n",
    "# モデルの各種設定\n",
    "args = train.get_args(target_col,bert_model,batch_sz,max_epochs,model,n_classes)\n",
    "dataloaders_dict = get_data_loaders(args,data_dict)\n",
    "\n",
    "# 学習\n",
    "train.train(args,dataloaders_dict)\n",
    "\n",
    "# モデルを名前を付けて保存\n",
    "shutil.copyfile('./savedir/mmbt_model_run/model_best.pt','./savedir/mmbt_model_run/'+save_model_name+'.pt')\n",
    "\n",
    "# 評価\n",
    "classification_report,confusion_matrix,detail_list,attention_probs = train.test(args,save_model_name,dataloaders_dict)\n",
    "# print(pd.DataFrame(classification_report).transpose())\n",
    "# 保存\n",
    "save_classification_report(classification_report)\n",
    "\n",
    "# 結果を保存\n",
    "df_result = get_df_result(classification_report)\n",
    "result_dir = './result/'\n",
    "save_pickle(df_result,result_dir+'df_result_'+save_model_name+'.pkl')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = get_df_result(classification_report)\n",
    "result_dir = './result/'\n",
    "save_pickle(df_result,result_dir+'df_result_'+save_model_name+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89066a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf725c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価\n",
    "classification_report,confusion_matrix,detail_list = train.test(args,save_model_name,dataloaders_dict,target_dataset)\n",
    "# print(pd.DataFrame(classification_report).transpose())\n",
    "# 保存\n",
    "save_classification_report(classification_report)\n",
    "\n",
    "# 結果を保存\n",
    "df_result = get_df_result()\n",
    "result_dir = './result/'\n",
    "save_pickle(df_result,result_dir+'result'+save_model_name+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba5312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# パラメータ更新を確認\n",
    "import glob\n",
    "import os\n",
    "\n",
    "files = glob.glob(\"./savedir/mmbt_model_run/*\")\n",
    "target_files =[]\n",
    "for file in files:\n",
    "    if 'epoch' in file:\n",
    "        target_files.append(file)\n",
    "dfs = []\n",
    "for file in target_files:\n",
    "    path = file\n",
    "    state_dict = load_pickle(path)\n",
    "    keys_list = list(state_dict.keys())\n",
    "    d = []\n",
    "    for k in keys_list:\n",
    "        p = state_dict[k]\n",
    "        \n",
    "        d.append({\n",
    "            \"epoch\":os.path.basename(path)[6],\n",
    "#             \"batch_cnt\":os.path.basename(path)[6],\n",
    "            \"name\": k,\n",
    "            \"dim\": p.shape,\n",
    "            \"val\": float(torch.sum(p)),\n",
    "            \"requires_grad\": p.requires_grad\n",
    "        })\n",
    "    vec_df =  pd.DataFrame(d)\n",
    "    dfs.append(vec_df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_s = df.sort_values(['name', 'epoch'], ascending=[True, True])\n",
    "df_s_gb = df_s.groupby(['name']).val.agg(['min', 'max'])\n",
    "df_s_gb['equal'] =  (df_s_gb['min'] == df_s_gb['max'])\n",
    "df_s_gb_not_equal = df_s_gb[df_s_gb['equal'] == False]\n",
    "df_s_gb_not_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e7f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ac7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_gb_equal = df_s_gb[df_s_gb['equal'] == True]\n",
    "df_s_gb_equal.to_csv(\"df_s_gb_equal.csv\")\n",
    "df_s_gb_equal_img_encoder = df_s_gb_equal.query('name.str.contains(\"img_encoder\")')\n",
    "df_s_gb_equal_img_encoder.to_csv(\"df_s_gb_equal_img_encoder.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b276d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfad448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ更新を確認\n",
    "import glob\n",
    "import os\n",
    "\n",
    "files = glob.glob(\"C:/Users/atom/git/mmbt-master/savedir/mmbt_model_run/*\")\n",
    "target_files =[]\n",
    "for file in files:\n",
    "    if 'batch' in file:\n",
    "        target_files.append(file)\n",
    "print(target_files)\n",
    "cnt = 0\n",
    "dfs = []\n",
    "for file in target_files:\n",
    "    path = file\n",
    "    state_dict = load_pickle(path)\n",
    "    keys_list = list(state_dict.keys())\n",
    "    d = []\n",
    "    for k in keys_list:\n",
    "        p = state_dict[k]\n",
    "        d.append({\n",
    "            \"epoch\":os.path.basename(path)[8],\n",
    "            \"batch_cnt\":os.path.basename(path)[6],\n",
    "            \"name\": k,\n",
    "            \"dim\": p.shape,\n",
    "            \"val\": float(torch.sum(p)),\n",
    "            \"requires_grad\": p.requires_grad\n",
    "        })\n",
    "    cnt += 1\n",
    "    vec_df =  pd.DataFrame(d)\n",
    "    dfs.append(vec_df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_s = df.sort_values(['name', 'epoch'], ascending=[True, True])\n",
    "df_s_gb = df_s.groupby(['name','epoch']).val.agg(['min', 'max'])\n",
    "df_s_gb['equal'] =  (df_s_gb['min'] == df_s_gb['max'])\n",
    "df_s_gb_not_equal = df_s_gb[df_s_gb['equal'] == False]\n",
    "df_s_gb_not_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e512e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "def get_mmbt_vec(i_epoch):\n",
    "\n",
    "    input_txt = load_pickle('./tmp/'+str(i_epoch)+'/'+'input_txt.pkl')\n",
    "    txt_embed_out = load_pickle('./tmp/'+str(i_epoch)+'/'+'txt_embed_out.pkl')\n",
    "    encoder_input = load_pickle('./tmp/'+str(i_epoch)+'/'+'encoder_input.pkl')\n",
    "    encoded_layers = load_pickle('./tmp/'+str(i_epoch)+'/'+'encoded_layers.pkl')\n",
    "    pooler = load_pickle('./tmp/'+str(i_epoch)+'/'+'self.pooler(encoded_layers[-1]).pkl')\n",
    "    return input_txt,txt_embed_out,encoder_input,encoded_layers,pooler\n",
    "\n",
    "i_epoch = 0\n",
    "input_txt_0,txt_embed_out_0,encoder_input_0,encoded_layers_0,pooler_0 = get_mmbt_vec(i_epoch)\n",
    "\n",
    "i_epoch = 1\n",
    "input_txt_1,txt_embed_out_1,encoder_input_1,encoded_layers_1,pooler_1 = get_mmbt_vec(i_epoch)\n",
    "\n",
    "i_epoch = 2\n",
    "input_txt_2,txt_embed_out_2,encoder_input_2,encoded_layers_2,pooler_2 = get_mmbt_vec(i_epoch)\n",
    "\n",
    "i_epoch = 3\n",
    "input_txt_3,txt_embed_out_3,encoder_input_3,encoded_layers_3,pooler_3 = get_mmbt_vec(i_epoch)\n",
    "\n",
    "i_epoch = 4\n",
    "input_txt_4,txt_embed_out_4,encoder_input_4,encoded_layers_4,pooler_4 = get_mmbt_vec(i_epoch)\n",
    "\n",
    "i_epoch = 5\n",
    "input_txt_5,txt_embed_out_5,encoder_input_5,encoded_layers_5,pooler_5 = get_mmbt_vec(i_epoch)\n",
    "\n",
    "i_epoch = 6\n",
    "input_txt_6,txt_embed_out_6,encoder_input_6,encoded_layers_6,pooler_6 = get_mmbt_vec(i_epoch)\n",
    "\n",
    "i_epoch = 7\n",
    "input_txt_7,txt_embed_out_7,encoder_input_7,encoded_layers_7,pooler_7 = get_mmbt_vec(i_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_layers_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f65464",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.vocab.stoi[\"[CLS]\"]\n",
    "args.vocab.itos[3244]#6\n",
    "args.vocab.itos[4524]#7　bag\n",
    "args.vocab.itos[7829]# shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae600d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4524：bag\n",
    "print(input_txt_0[0][4])# bagの単語id\n",
    "print(input_txt_0[2][10])# bagの単語id\n",
    "# print(txt_embed_out_1[1][3]) # bagの768次元ベクトル\n",
    "v1 = txt_embed_out_0[2][10].to('cpu').detach().numpy().copy()\n",
    "sum(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コサイン類似度を調べる bag\n",
    "def get_i_epoch_vec_list():\n",
    "    i_epoch = 0\n",
    "    i_epoch_vec_list = []\n",
    "    for i in range(8):\n",
    "        epoch_num = i\n",
    "        txt_embed_out = load_pickle('./tmp/'+str(epoch_num)+'/'+'txt_embed_out.pkl')\n",
    "        v1 = txt_embed_out[0][4].to('cpu').detach().numpy().copy()\n",
    "        i_epoch_vec = [epoch_num,'bag',sum(v1)]\n",
    "        i_epoch_vec_list.append(i_epoch_vec)\n",
    "    return i_epoch_vec_list\n",
    "i_epoch_vec_list = get_i_epoch_vec_list()\n",
    "df_i_epoch_vec = pd.DataFrame(i_epoch_vec_list,\n",
    "                  columns=['i_epoch','token_name', 'sum_txt_embed_out' ])\n",
    "\n",
    "df_i_epoch_vec.to_csv('df_i_epoch_vec_step_false.csv')\n",
    "df_i_epoch_vec\n",
    "# v2 = txt_embed_out_7[2][10].to('cpu').detach().numpy().copy()\n",
    "# print(('sum(v1)',sum(v1)),('sum(v2)',sum(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7fa51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e287cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2つ文章に登場するbagの単語類似度を算出\n",
    "v1 = encoder_input_1[1][10].to('cpu').detach().numpy().copy() # encoder_input_1[3][1:3]はRGBだから画像部分のベクトル変化する\n",
    "v2 = encoder_input_5[4][2].to('cpu').detach().numpy().copy()\n",
    "# v2 = encoder_input_5[3][1].to('cpu').detach().numpy().copy()\n",
    "print(cos_sim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2つ文章に登場するbagの単語類似度を算出\n",
    "v1 = txt_embed_out_0[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_0[4][2].to('cpu').detach().numpy().copy()\n",
    "print(cos_sim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aab527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コサイン類似度を調べる bag\n",
    "v1 = txt_embed_out_7[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_7[4][2].to('cpu').detach().numpy().copy()\n",
    "print(cos_sim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b567da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コサイン類似度を調べる bag\n",
    "v1 = txt_embed_out_0[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_1[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_2[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_3[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_4[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_5[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_6[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_7[1][10].to('cpu').detach().numpy().copy()\n",
    "print(cos_sim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# コサイン類似度を調べる bag\n",
    "v1 = encoded_layers_0[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = encoded_layers_1[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = encoded_layers_2[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = encoded_layers_3[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = encoded_layers_4[1][10].to('cpu').detach().numpy().copy()\n",
    "v2 = encoded_layers_5[1][10].to('cpu').detach().numpy().copy()\n",
    "# v2 = encoded_layers_6[1][10].to('cpu').detach().numpy().copy()\n",
    "# v2 = encoded_layers_7[1][10].to('cpu').detach().numpy().copy()\n",
    "print(cos_sim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コサイン類似度を調べる\n",
    "v1 = txt_embed_out_1[1][3].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_1[3][4].to('cpu').detach().numpy().copy()\n",
    "print(cos_sim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6e736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212d6e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_2d_vector(vec):\n",
    "    df = pd.DataFrame(vec)\n",
    "    model_tsne = TSNE(n_components=2, perplexity=2)\n",
    "    vecs_list = model_tsne.fit_transform(df)\n",
    "    df_add_vecs_list =  pd.DataFrame(vecs_list)\n",
    "    return df_add_vecs_list,vecs_list\n",
    "# v1 = encoder_input[0][7].to('cpu').detach().numpy().copy()\n",
    "# v2 = encoded_layers[0][7].to('cpu').detach().numpy().copy()\n",
    "\n",
    "v1 = txt_embed_out_1[4][0].to('cpu').detach().numpy().copy()\n",
    "v2 = txt_embed_out_2[4][0].to('cpu').detach().numpy().copy()\n",
    "\n",
    "print(cos_sim(v1, v2))\n",
    "df_add_vecs_list_v1,v1_2d = get_2d_vector(v1)\n",
    "df_add_vecs_list_v2,v2_2d = get_2d_vector(v2)\n",
    "df_add_vecs_list_v1['name'] = 'encoder_input[0][7]'\n",
    "df_add_vecs_list_v2['name'] = 'encoded_layers[0][7]'\n",
    "df_add_vecs_list_cat = pd.concat([df_add_vecs_list_v1, df_add_vecs_list_v2])\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "sns.set(font=\"Hiragino Maru Gothic Pro\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title('bag_vector')\n",
    "sns.scatterplot(data=df_add_vecs_list_cat, x=0, y=1, hue='name')\n",
    "# for i,(x_name,y_name) in enumerate(zip(X,Y)):\n",
    "#     plt.annotate(df.index[i],(x_name,y_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in range(32):\n",
    "    try:\n",
    "        new_dir_path = './tmp/'+str(i)\n",
    "        os.mkdir(new_dir_path)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daab27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop atomアカウント"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817e8db",
   "metadata": {},
   "source": [
    "# 本番データで予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30880369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用データセットを定義\n",
    "target_dataset = 'ebay_20210822_msg_prediction'\n",
    "\n",
    "# データ読み込み\n",
    "df = pd.read_table('./datasets/'+target_dataset+'/data.tsv')\n",
    "\n",
    "# カラム追加\n",
    "df_addcol = get_df_addcol(df)\n",
    "\n",
    "# 推論\n",
    "model_name = 'model_msg_cnt_flag_variables3_ep20' # MSGの有無を予測するモデル\n",
    "df_preprocessed_msg = get_preds_score(df,model_name)\n",
    "\n",
    "# 推論\n",
    "model_name = 'model_sold_flag_variables3_ep20' # soldの有無を予測するモデル\n",
    "df_preprocessed_sold = get_preds_score(df,model_name)\n",
    "\n",
    "# 推論結果を元データに追加\n",
    "df_preprocessed_msg = df_preprocessed_msg.rename(columns={'preds_score': 'msg_preds_score'})\n",
    "df_preprocessed_msg = df_preprocessed_msg.loc[:,['img','msg_preds_score']]\n",
    "df_add_msg_preds_score =pd.merge(df_addcol, df_preprocessed_msg, how='left',on='img')\n",
    "\n",
    "# 推論結果を元データに追加\n",
    "df_preprocessed_sold = df_preprocessed_sold.rename(columns={'preds_score': 'sold_preds_score'})\n",
    "df_preprocessed_sold = df_preprocessed_sold.loc[:,['img','sold_preds_score']]\n",
    "df_add_msg_sold_preds_score = pd.merge(df_add_msg_preds_score, df_preprocessed_sold, how='left',on='img')\n",
    "df_add_msg_sold_preds_score.head(1)\n",
    "\n",
    "# 結果を保存\n",
    "df_add_msg_sold_preds_score.to_csv('./tmp/ebay_20210822_msg_prediction/add_preds_score_data.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "# データをロード\n",
    "df_add_msg_sold_preds_score = pd.read_table('./tmp/ebay_20210822_msg_prediction/add_preds_score_data.tsv')\n",
    "\n",
    "# 推論結果をいい感じに整形\n",
    "df_add_msg_sold_preds_score['msg_first_pred_score'] = df_add_msg_sold_preds_score.msg_preds_score.apply(lambda x:get_first_pred_score(x))\n",
    "df_add_msg_sold_preds_score['sold_first_pred_score'] = df_add_msg_sold_preds_score.sold_preds_score.apply(lambda x:get_first_pred_score(x))\n",
    "df_add_msg_sold_preds_score['msg_pred'] = df_add_msg_sold_preds_score.msg_preds_score.apply(lambda x:get_pred(x))\n",
    "df_add_msg_sold_preds_score['sold_pred'] = df_add_msg_sold_preds_score.sold_preds_score.apply(lambda x:get_pred(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efd849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmbt.models import get_model\n",
    "from mmbt.utils.utils import *\n",
    "target_dataset = 'ebay_20210822_msg_prediction'\n",
    "model_name = '20210816_msgcntflag_no1_title_img_stdprice_ep20'\n",
    "model = get_model(args)\n",
    "load_checkpoint(model, './savedir/'+target_dataset+'/mmbt_model_run/'+model_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3e359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = [('a','b'),('c','d'),('e','f')]\n",
    "no_decay = ['e', 'b']\n",
    "optimizer_grouped_parameters =[\n",
    "    {'params':[p for n, p in param_optimizer if not any((nd in n for nd in no_decay))], \n",
    "    'weight_decay':0.01},\n",
    "    {'params':[p for n, p in param_optimizer if any((nd in n for nd in no_decay))],'weight_decay':0.0}]\n",
    "optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for n, p in param_optimizer if not any((nd in n for nd in no_decay))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82284bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# 価格をカテゴリごとに標準化\n",
    "class_ = df[['ctg']]\n",
    "class_names = df.groupby('ctg').groups.keys()\n",
    "data = []\n",
    "for name in class_names:\n",
    "    df_tmp = df[(df['ctg'] == name)].drop(columns=['ctg'])\n",
    "    df_tmp['std_price'] = (df_tmp['price_x'] - df_tmp['price_x'].mean())/df_tmp['price_x'].std()    \n",
    "    df_ = pd.concat([df_, df_tmp])\n",
    "df_['ctg'] = class_\n",
    "\n",
    "# 前処理\n",
    "df_tmp = df_\n",
    "# カテゴリー分類の際は、IDを指定する\n",
    "if target_col == 'ctg':\n",
    "    df_tmp = df_tmp.astype({'ctg': str})\n",
    "    df_tmp = df_tmp[df_tmp['ctg'].isin(['69528','183454','180506','169291','15687'])]\n",
    "df_tmp[\"fullpath\"] = df_tmp.itemid.apply(lambda x: \"images/\" + str(x) + \".jpg\")\n",
    "df_tmp['error_imgfile_flg'] = df_tmp['fullpath'].swifter.apply(lambda x:error_imagefile_serch(x))\n",
    "df_tmp = df_tmp[df_tmp['error_imgfile_flg']==0]\n",
    "df_tmp[\"label\"] = df_tmp[target_col]\n",
    "df_tmp['date'] = df_tmp['dt'].apply(lambda x: x[5:7])\n",
    "df_tmp['img'] = './datasets/' + df_tmp['fullpath']\n",
    "df_tmp[\"text\"] = df_tmp['title'].str.lower()\n",
    "df_tmp[\"text\"] = df_tmp['text'].apply(lambda x: \" \".join(re.findall(r\"[ぁ-んァ-ン一-龥ー'\\da-zA-Z\\-]+\", x)))\n",
    "\n",
    "df_preprocessed = df_tmp.loc[:,['label','text','img','date','std_price']].reset_index(drop=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30259c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dev,df_test = train_test_split(df_preprocessed, random_state=0,stratify=df_preprocessed.label)\n",
    "# 最小データ数でダウンサンプリング\n",
    "minimum_num = df_train_dev['label'].value_counts().min()\n",
    "# ラベル毎に最小データ数だけサンプリング\n",
    "dfs = [d.sample(minimum_num, random_state=0) for name, d in df_train_dev.groupby('label')]\n",
    "# 結合。ラベル順に並んでいるのでshuffleする\n",
    "under_resampled_df = pd.concat(dfs).sample(frac=1, random_state=0)\n",
    "df_train_dev = under_resampled_df\n",
    "df_train, df_dev = train_test_split(df_train_dev,stratify=df_train_dev.label)\n",
    "data_dict = {\"train\": df_train, \"val\": df_dev,'test':df_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f632d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.groupby('ctg').count().sort_values('itemid', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d8d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaaadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf05944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmbt.models import get_model\n",
    "from mmbt.utils.utils import *\n",
    "model = get_model(args)\n",
    "load_checkpoint(model, './savedir/ebay_codes_20210815_message_prediction/mmbt_model_run/model_best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c59b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コサイン類似度を調べる bag\n",
    "target_layers = 'encoded_layers'\n",
    "def get_i_epoch_vec_list():\n",
    "    i_epoch = 0\n",
    "    i_epoch_vec_list = []\n",
    "    for i in range(8):\n",
    "        epoch_num = i\n",
    "        encoded_layers = load_pickle('./tmp/'+str(epoch_num)+'/'+target_layers+'.pkl')\n",
    "        v1 = encoded_layers[0][4].to('cpu').detach().numpy().copy()\n",
    "        i_epoch_vec = [epoch_num,'bag',sum(v1)]\n",
    "        i_epoch_vec_list.append(i_epoch_vec)\n",
    "    return i_epoch_vec_list\n",
    "i_epoch_vec_list = get_i_epoch_vec_list()\n",
    "df_i_epoch_vec = pd.DataFrame(i_epoch_vec_list,\n",
    "                  columns=['i_epoch','token_name', 'sum_txt_embed_out' ])\n",
    "df_i_epoch_vec\n",
    "# v2 = txt_embed_out_7[2][10].to('cpu').detach().numpy().copy()\n",
    "# print(('sum(v1)',sum(v1)),('sum(v2)',sum(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb12feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "\n",
    "target_layer = model.module.features\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "gradcam_pp = GradCAMpp(model, target_layer)\n",
    "\n",
    "\n",
    "production_loader = dataloaders_dict['production']\n",
    "model = get_model(args)\n",
    "load_checkpoint(model, './savedir/mmbt_model_run/model_best.pt')\n",
    "criterion = get_criterion(args)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ネットワークをGPUへ\n",
    "model.to(device)\n",
    "\n",
    "# 評価\n",
    "# preds_score = model_production(production_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本番データでの予測の際に使用する関数\n",
    "# 予測値の確率を出力\n",
    "\n",
    "    target_dataset = 'ebay_codes_20210815_message_prediction' # データセット名\n",
    "    model = 'mmbt'\n",
    "    bert_model = 'bert-base-uncased' # bertモデル　bert-large-uncased　bert-base-uncased\n",
    "    image_model = 'resnet152' # imageモデル\n",
    "    batch_sz = '32' # 不要\n",
    "    max_epochs = '10' # 不要\n",
    "    target_col = 'none' # 不要\n",
    "    \n",
    "    # データ読み込み\n",
    "    df = df.loc[:][['mk_title','url','selling_price','category_id']]\n",
    "    df['title'] = df['mk_title']\n",
    "\n",
    "    # 前処理\n",
    "    categoryid = 'category_id'\n",
    "    price = 'selling_price'\n",
    "    df_preprocessed = get_preprocessed_data_for_production(df,categoryid,price)\n",
    "    # データセット作成＆保存\n",
    "    data_dict = get_dataset_for_production(df_preprocessed)\n",
    "    # モデルの各種設定\n",
    "    args = train.get_args(target_col,bert_model,batch_sz,max_epochs,model)\n",
    "    dataloaders_dict = get_data_loaders_for_production(args,data_dict)\n",
    "\n",
    "    # 評価\n",
    "    preds_score = train.production(args,model_name,dataloaders_dict)\n",
    "    df_preprocessed['preds_score'] = preds_score\n",
    "    df_preprocessed = df_preprocessed.reset_index(drop=True)\n",
    "    df_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ee183",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = 'ebay_codes_20210815_message_prediction' # データセット名\n",
    "\n",
    "# データ読み込み\n",
    "df = pd.read_table('./datasets/'+target_dataset+'/data.tsv')\n",
    "\n",
    "# カラム追加\n",
    "df_addcol = get_df_addcol(df)\n",
    "\n",
    "# 推論\n",
    "model_name = 'model_best' # MSGの有無を予測するモデル\n",
    "\n",
    "\n",
    "model = 'mmbt'\n",
    "bert_model = 'bert-base-uncased' # bertモデル　bert-large-uncased　bert-base-uncased\n",
    "image_model = 'resnet152' # imageモデル\n",
    "batch_sz = '32' # 不要\n",
    "max_epochs = '10' # 不要\n",
    "target_col = 'none' # 不要\n",
    "\n",
    "# データ読み込み\n",
    "df = df.loc[:][['mk_title','url','selling_price','category_id']]\n",
    "df['title'] = df['mk_title']\n",
    "\n",
    "# 前処理\n",
    "categoryid = 'category_id'\n",
    "price = 'selling_price'\n",
    "df_preprocessed = get_preprocessed_data_for_production(df,target_dataset,categoryid,price)\n",
    "# データセット作成＆保存\n",
    "data_dict = get_dataset_for_production(df_preprocessed)\n",
    "# モデルの各種設定\n",
    "args = train.get_args(target_col,bert_model,batch_sz,max_epochs,model)\n",
    "dataloaders_dict = get_data_loaders_for_production(args,data_dict)\n",
    "\n",
    "# 評価\n",
    "preds_score = train.production(args,model_name,dataloaders_dict)\n",
    "df_preprocessed['preds_score'] = preds_score\n",
    "df_preprocessed = df_preprocessed.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b901a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5455da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Basic Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "# Grad-CAM\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from mmbt.models import get_model\n",
    "from mmbt.utils.utils import *\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.img_encoder = model.enc.img_encoder\n",
    "        self.img_embeddings = model.enc.img_embeddings\n",
    "        self.num_image_embeds = 3\n",
    "    def forword(self, img_input):\n",
    "        img_tok = (\n",
    "            torch.LongTensor(32, self.num_image_embeds)\n",
    "            .fill_(0)\n",
    "            .cuda()\n",
    "        )\n",
    "        img = self.img_encoder(input_img)  # BxNx3x224x224 -> BxNx2048\n",
    "        img_embed_out = self.img_embeddings(img, img_tok)\n",
    "        return img_embed_out\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()  else \"cpu\")\n",
    "\n",
    "# model.fc = nn.Linear(2048,5)\n",
    "# model = torch.nn.DataParallel(model).to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_criterion(args):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion\n",
    "\n",
    "# Grad-CAM\n",
    "\n",
    "\n",
    "# target_layer = model.enc.img_encoder\n",
    "# resnet = Resnet()\n",
    "model_resnet = models.resnet152(pretrained=True)\n",
    "target_layer_resnet = model_resnet.layer4\n",
    "# modules = list(model.children())[:-2]\n",
    "# model = nn.Sequential(*modules)\n",
    "\n",
    "gradcam = GradCAM(model_resnet, target_layer_resnet)\n",
    "gradcam_pp = GradCAMpp(model_resnet, target_layer_resnet)\n",
    "\n",
    "images = []\n",
    "# img = Image.open('./datasets/ebay_codes_20210815_message_prediction/images/324727872736.jpg')\n",
    "img = Image.open('./datasets/ebay_codes_20210815_message_prediction/images/255066960205.jpg')\n",
    "torch_img = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])(img)\n",
    "normed_torch_img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(torch_img)[None]\n",
    "\n",
    "# normed_torch_img = normed_torch_img.unsqueeze(0)\n",
    "mask, _ = gradcam(normed_torch_img)\n",
    "heatmap, result = visualize_cam(mask, torch_img)\n",
    "\n",
    "mask_pp, _ = gradcam_pp(normed_torch_img)\n",
    "heatmap_pp, result_pp = visualize_cam(mask_pp, torch_img)\n",
    "\n",
    "images.extend([torch_img.cpu(), heatmap, heatmap_pp, result, result_pp])\n",
    "grid_image = make_grid(images, nrow=5)\n",
    "\n",
    "# 結果の表示\n",
    "transforms.ToPILImage()(grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3624d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#貼り付け\n",
    "\n",
    "plt.imshow(Image.fromarray(np.array(torch_img)))\n",
    "#表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c824cf",
   "metadata": {},
   "source": [
    "# MMBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370d011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "# Grad-CAM\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from mmbt.models import get_model\n",
    "from mmbt.utils.utils import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()  else \"cpu\")\n",
    "\n",
    "\n",
    "# model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "def get_criterion(args):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion\n",
    "\n",
    "# Grad-CAM\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.img_encoder = model.enc.img_encoder\n",
    "        self.img_embeddings = model.enc.img_embeddings\n",
    "        self.num_image_embeds = 5\n",
    "    def forward(self, img_input):\n",
    "        \n",
    "        img_tok = (\n",
    "            torch.LongTensor(1, self.num_image_embeds)\n",
    "            .fill_(0).to(device)\n",
    "        )\n",
    "        img = self.img_encoder(img_input).to(device) # BxNx3x224x224 -> BxNx2048\n",
    "        img = self.img_embeddings(img, img_tok).to(device)\n",
    "        return torch.flatten(img, start_dim=1).to(device)\n",
    "       \n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.img_encoder = model.enc.img_encoder\n",
    "        self.img_embeddings = model.enc.img_embeddings\n",
    "        \n",
    "    def forward(self, img_input):\n",
    "\n",
    "        img = self.img_encoder(img_input)  # BxNx3x224x224 -> BxNx2048\n",
    "        return torch.flatten(img, start_dim=1)\n",
    "    \n",
    "model = get_model(args).to(device)\n",
    "load_checkpoint(model, './savedir/mmbt_model_run/model_best.pt')\n",
    "model.eval()\n",
    "\n",
    "target_layer = model.enc.img_encoder.model[4]\n",
    "# resnet = torchvision.models.resnet152(pretrained=True)\n",
    "# model.fc = nn.Linear(2048,5)\n",
    "\n",
    "resnet = Resnet()\n",
    "gradcam = GradCAM(resnet, target_layer)\n",
    "gradcam_pp = GradCAMpp(resnet, target_layer)\n",
    "\n",
    "images = []\n",
    "# img = Image.open('./datasets/ebay_codes_20210815_message_prediction/images/324727872736.jpg')\n",
    "img = Image.open('./datasets/ebay_codes_20210815_message_prediction/images/255066960205.jpg')\n",
    "\n",
    "\n",
    "# torch_img = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor()\n",
    "# ])(img)\n",
    "\n",
    "# torch_img = transforms.Compose(\n",
    "#         [\n",
    "#             transforms.Resize(256),\n",
    "#             transforms.CenterCrop(224),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(\n",
    "#                 mean=[0.46777044, 0.44531429, 0.40661017],\n",
    "#                 std=[0.12221994, 0.12145835, 0.14380469],\n",
    "#             ),\n",
    "#         ]\n",
    "#     )(img).to(device)\n",
    "\n",
    "torch_img = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])(img)\n",
    "normed_torch_img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(torch_img)[None].to(device)\n",
    "\n",
    "# normed_torch_img = torch_img.unsqueeze(0)\n",
    "\n",
    "# normed_torch_img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(torch_img)[None]\n",
    "\n",
    "# normed_torch_img = normed_torch_img.unsqueeze(0)\n",
    "mask, _ = gradcam(normed_torch_img)\n",
    "heatmap, result = visualize_cam(mask, torch_img)\n",
    "\n",
    "mask_pp, _ = gradcam_pp(normed_torch_img)\n",
    "heatmap_pp, result_pp = visualize_cam(mask_pp, torch_img)\n",
    "\n",
    "images.extend([torch_img.cpu(), heatmap, heatmap_pp, result, result_pp])\n",
    "grid_image = make_grid(images, nrow=5)\n",
    "\n",
    "# 結果の表示\n",
    "transforms.ToPILImage()(grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b006e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2318d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb653fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
